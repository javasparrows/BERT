{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MeCabなどをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt install aptitude swig\n",
    "# !sudo aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mecab-python3==0.996.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeCabで新語（最近の新しい言葉）を使えるように、辞書であるNEologdをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mecab-ipadic-neologd'...\n",
      "remote: Enumerating objects: 75, done.\u001b[K\n",
      "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
      "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
      "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (75/75), 58.02 MiB | 9.23 MiB/s, done.\n",
      "Updating files: 100% (65/65), done.\n",
      "[install-mecab-ipadic-NEologd] : Start..\n",
      "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
      "[install-mecab-ipadic-NEologd] :     find => ok\n",
      "[install-mecab-ipadic-NEologd] :     sort => ok\n",
      "[install-mecab-ipadic-NEologd] :     head => ok\n",
      "[install-mecab-ipadic-NEologd] :     cut => ok\n",
      "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
      "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
      "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
      "[install-mecab-ipadic-NEologd] :     make => ok\n",
      "[install-mecab-ipadic-NEologd] :     curl => ok\n",
      "[install-mecab-ipadic-NEologd] :     sed => ok\n",
      "[install-mecab-ipadic-NEologd] :     cat => ok\n",
      "[install-mecab-ipadic-NEologd] :     diff => ok\n",
      "[install-mecab-ipadic-NEologd] :     tar => ok\n",
      "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
      "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
      "[install-mecab-ipadic-NEologd] :     grep => ok\n",
      "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
      "[install-mecab-ipadic-NEologd] :     patch => ok\n",
      "[install-mecab-ipadic-NEologd] :     which => ok\n",
      "[install-mecab-ipadic-NEologd] :     file => ok\n",
      "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
      "[install-mecab-ipadic-NEologd] :     awk => ok\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd is already up-to-date\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd will be install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : Make mecab-ipadic-NEologd\n",
      "[make-mecab-ipadic-NEologd] : Start..\n",
      "[make-mecab-ipadic-NEologd] : Check local seed directory\n",
      "[make-mecab-ipadic-NEologd] : Check local seed file\n",
      "[make-mecab-ipadic-NEologd] : Check local build directory\n",
      "[make-mecab-ipadic-NEologd] : create /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../build\n",
      "[make-mecab-ipadic-NEologd] : Download original mecab-ipadic file\n",
      "[make-mecab-ipadic-NEologd] : Try to access to https://ja.osdn.net\n",
      "[make-mecab-ipadic-NEologd] : Try to download from https://ja.osdn.net/frs/g_redir.php?m=kent&f=mecab%2Fmecab-ipadic%2F2.7.0-20070801%2Fmecab-ipadic-2.7.0-20070801.tar.gz\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 11.6M  100 11.6M    0     0  9622k      0  0:00:01  0:00:01 --:--:-- 18.7M\n",
      "Hash value of /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801.tar.gz matched\n",
      "[make-mecab-ipadic-NEologd] : Decompress original mecab-ipadic file\n",
      "mecab-ipadic-2.7.0-20070801/\n",
      "mecab-ipadic-2.7.0-20070801/README\n",
      "mecab-ipadic-2.7.0-20070801/AUTHORS\n",
      "mecab-ipadic-2.7.0-20070801/COPYING\n",
      "mecab-ipadic-2.7.0-20070801/ChangeLog\n",
      "mecab-ipadic-2.7.0-20070801/INSTALL\n",
      "mecab-ipadic-2.7.0-20070801/Makefile.am\n",
      "mecab-ipadic-2.7.0-20070801/Makefile.in\n",
      "mecab-ipadic-2.7.0-20070801/NEWS\n",
      "mecab-ipadic-2.7.0-20070801/aclocal.m4\n",
      "mecab-ipadic-2.7.0-20070801/config.guess\n",
      "mecab-ipadic-2.7.0-20070801/config.sub\n",
      "mecab-ipadic-2.7.0-20070801/configure\n",
      "mecab-ipadic-2.7.0-20070801/configure.in\n",
      "mecab-ipadic-2.7.0-20070801/install-sh\n",
      "mecab-ipadic-2.7.0-20070801/missing\n",
      "mecab-ipadic-2.7.0-20070801/mkinstalldirs\n",
      "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
      "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
      "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
      "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
      "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
      "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
      "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
      "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
      "mecab-ipadic-2.7.0-20070801/Others.csv\n",
      "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
      "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
      "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
      "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
      "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
      "mecab-ipadic-2.7.0-20070801/Verb.csv\n",
      "mecab-ipadic-2.7.0-20070801/char.def\n",
      "mecab-ipadic-2.7.0-20070801/feature.def\n",
      "mecab-ipadic-2.7.0-20070801/left-id.def\n",
      "mecab-ipadic-2.7.0-20070801/matrix.def\n",
      "mecab-ipadic-2.7.0-20070801/pos-id.def\n",
      "mecab-ipadic-2.7.0-20070801/rewrite.def\n",
      "mecab-ipadic-2.7.0-20070801/right-id.def\n",
      "mecab-ipadic-2.7.0-20070801/unk.def\n",
      "mecab-ipadic-2.7.0-20070801/dicrc\n",
      "mecab-ipadic-2.7.0-20070801/RESULT\n",
      "[make-mecab-ipadic-NEologd] : Configure custom system dictionary on /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200820\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking for working aclocal-1.4... missing\n",
      "checking for working autoconf... missing\n",
      "checking for working automake-1.4... missing\n",
      "checking for working autoheader... missing\n",
      "checking for working makeinfo... missing\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking for mecab-config... /usr/bin/mecab-config\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "[make-mecab-ipadic-NEologd] : Encode the character encoding of system dictionary resources from EUC_JP to UTF-8\n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
      "rm ./Noun.others.csv \n",
      "rm ./Verb.csv \n",
      "rm ./Postp-col.csv \n",
      "rm ./Noun.number.csv \n",
      "rm ./Noun.adjv.csv \n",
      "rm ./Noun.csv \n",
      "rm ./Symbol.csv \n",
      "rm ./Noun.proper.csv \n",
      "rm ./Others.csv \n",
      "rm ./Noun.demonst.csv \n",
      "rm ./Prefix.csv \n",
      "rm ./Noun.org.csv \n",
      "rm ./Noun.name.csv \n",
      "rm ./Adj.csv \n",
      "rm ./Adverb.csv \n",
      "rm ./Interjection.csv \n",
      "rm ./Noun.nai.csv \n",
      "rm ./Noun.verbal.csv \n",
      "rm ./Auxil.csv \n",
      "rm ./Postp.csv \n",
      "rm ./Adnominal.csv \n",
      "rm ./Suffix.csv \n",
      "rm ./Conjunction.csv \n",
      "rm ./Noun.place.csv \n",
      "rm ./Noun.adverbal.csv \n",
      "rm ./Filler.csv \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
      "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
      "rm ./rewrite.def \n",
      "rm ./matrix.def \n",
      "rm ./left-id.def \n",
      "rm ./pos-id.def \n",
      "rm ./feature.def \n",
      "rm ./unk.def \n",
      "rm ./right-id.def \n",
      "rm ./char.def \n",
      "mv ./char.def.utf8 ./char.def \n",
      "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
      "mv ./pos-id.def.utf8 ./pos-id.def \n",
      "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
      "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
      "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
      "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
      "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
      "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
      "mv ./Noun.csv.utf8 ./Noun.csv \n",
      "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
      "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
      "mv ./matrix.def.utf8 ./matrix.def \n",
      "mv ./Adj.csv.utf8 ./Adj.csv \n",
      "mv ./rewrite.def.utf8 ./rewrite.def \n",
      "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
      "mv ./Filler.csv.utf8 ./Filler.csv \n",
      "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
      "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
      "mv ./right-id.def.utf8 ./right-id.def \n",
      "mv ./Others.csv.utf8 ./Others.csv \n",
      "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
      "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
      "mv ./unk.def.utf8 ./unk.def \n",
      "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
      "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
      "mv ./Postp.csv.utf8 ./Postp.csv \n",
      "mv ./feature.def.utf8 ./feature.def \n",
      "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
      "mv ./left-id.def.utf8 ./left-id.def \n",
      "mv ./Verb.csv.utf8 ./Verb.csv \n",
      "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
      "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
      "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
      "[make-mecab-ipadic-NEologd] : Fix yomigana field of IPA dictionary\n",
      "patching file Noun.csv\n",
      "patching file Noun.place.csv\n",
      "patching file Verb.csv\n",
      "patching file Noun.verbal.csv\n",
      "patching file Noun.name.csv\n",
      "patching file Noun.adverbal.csv\n",
      "patching file Noun.csv\n",
      "patching file Noun.name.csv\n",
      "patching file Noun.org.csv\n",
      "patching file Noun.others.csv\n",
      "patching file Noun.place.csv\n",
      "patching file Noun.proper.csv\n",
      "patching file Noun.verbal.csv\n",
      "patching file Prefix.csv\n",
      "patching file Suffix.csv\n",
      "patching file Noun.proper.csv\n",
      "patching file Noun.csv\n",
      "patching file Noun.name.csv\n",
      "patching file Noun.org.csv\n",
      "patching file Noun.place.csv\n",
      "patching file Noun.proper.csv\n",
      "patching file Noun.verbal.csv\n",
      "patching file Noun.name.csv\n",
      "patching file Noun.org.csv\n",
      "patching file Noun.place.csv\n",
      "patching file Noun.proper.csv\n",
      "patching file Suffix.csv\n",
      "patching file Noun.demonst.csv\n",
      "patching file Noun.csv\n",
      "patching file Noun.name.csv\n",
      "[make-mecab-ipadic-NEologd] : Copy user dictionary resource\n",
      "[make-mecab-ipadic-NEologd] : Install adverb entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-adverb-dict-seed.20150623.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install interjection entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-interjection-dict-seed.20170216.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install entries of orthographic variant of a noun used as verb form using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install frequent adjective orthographic variant entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-std-dict-seed.20151126.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install infrequent adjective orthographic variant entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-exp-dict-seed.20151126.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install adjective verb orthographic variant entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-verb-dict-seed.20160324.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install infrequent datetime representation entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-date-time-infreq-dict-seed.20190415.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install infrequent quantity representation entries using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-quantity-infreq-dict-seed.20190415.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Install entries of ill formed words using /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../seed/neologd-ill-formed-words-dict-seed.20170127.csv.xz\n",
      "[make-mecab-ipadic-NEologd] : Re-Index system dictionary\n",
      "reading ./unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "reading ./Noun.others.csv ... 153\n",
      "reading ./Verb.csv ... 130750\n",
      "reading ./Postp-col.csv ... 91\n",
      "reading ./neologd-adjective-verb-dict-seed.20160324.csv ... 20268\n",
      "reading ./Noun.number.csv ... 42\n",
      "reading ./Noun.adjv.csv ... 3328\n",
      "reading ./Noun.csv ... 60734\n",
      "reading ./Symbol.csv ... 208\n",
      "reading ./Noun.proper.csv ... 27493\n",
      "reading ./Others.csv ... 2\n",
      "reading ./neologd-proper-noun-ortho-variant-dict-seed.20161110.csv ... 138379\n",
      "reading ./Noun.demonst.csv ... 120\n",
      "reading ./Prefix.csv ... 224\n",
      "reading ./Noun.org.csv ... 17149\n",
      "reading ./Noun.name.csv ... 34215\n",
      "reading ./Adj.csv ... 27210\n",
      "reading ./Adverb.csv ... 3032\n",
      "reading ./Interjection.csv ... 252\n",
      "reading ./Noun.nai.csv ... 42\n",
      "reading ./Noun.verbal.csv ... 12150\n",
      "reading ./Auxil.csv ... 199\n",
      "reading ./Postp.csv ... 146\n",
      "reading ./Adnominal.csv ... 135\n",
      "reading ./neologd-quantity-infreq-dict-seed.20190415.csv ... 229216\n",
      "reading ./Suffix.csv ... 1448\n",
      "reading ./neologd-interjection-dict-seed.20170216.csv ... 4701\n",
      "reading ./neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv ... 26058\n",
      "reading ./Conjunction.csv ... 171\n",
      "reading ./Noun.place.csv ... 73194\n",
      "reading ./mecab-user-dict-seed.20200820.csv ... 3219806\n",
      "reading ./Noun.adverbal.csv ... 808\n",
      "reading ./neologd-adjective-exp-dict-seed.20151126.csv ... 1051146\n",
      "reading ./neologd-date-time-infreq-dict-seed.20190415.csv ... 16866\n",
      "reading ./neologd-ill-formed-words-dict-seed.20170127.csv ... 60616\n",
      "reading ./neologd-adverb-dict-seed.20150623.csv ... 139792\n",
      "reading ./Filler.csv ... 19\n",
      "reading ./neologd-common-noun-ortho-variant-dict-seed.20170228.csv ... 152869\n",
      "reading ./neologd-adjective-std-dict-seed.20151126.csv ... 507812\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1316x1316\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "[make-mecab-ipadic-NEologd] : Make custom system dictionary on /shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200820\n",
      "make: Nothing to be done for 'all'.\n",
      "[make-mecab-ipadic-NEologd] : Finish..\n",
      "[install-mecab-ipadic-NEologd] : Get results of tokenize test\n",
      "[test-mecab-ipadic-NEologd] : Start..\n",
      "[test-mecab-ipadic-NEologd] : Replace timestamp from 'git clone' date to 'git commit' date\n",
      "[test-mecab-ipadic-NEologd] : Get buzz phrases\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1632  100  1632    0     0  13714      0 --:--:-- --:--:-- --:--:-- 13714\n",
      "[test-mecab-ipadic-NEologd] : Get difference between default system dictionary and mecab-ipadic-NEologd\n",
      "[test-mecab-ipadic-NEologd] : Tokenize phrase using default system dictionary\n",
      "[test-mecab-ipadic-NEologd] : Tokenize phrase using mecab-ipadic-NEologd\n",
      "[test-mecab-ipadic-NEologd] : Get result of diff\n",
      "[test-mecab-ipadic-NEologd] : Please check difference between default system dictionary and mecab-ipadic-NEologd\n",
      "\n",
      "default system dictionary\t  |\tmecab-ipadic-NEologd\n",
      "高橋 幸宏 \t\t\t  |\t高橋幸宏 \n",
      "ビッグ ボーイ \t\t\t  |\tビッグボーイ \n",
      "5 期生 \t\t\t\t  |\t5期生 \n",
      "渡邉 雄大 \t\t\t  |\t渡邉雄大 \n",
      "野菜 の 日 \t\t\t  |\t野菜の日 \n",
      "しいたけ 占い \t\t\t  |\tしいたけ占い \n",
      "牧野 由依 \t\t\t  |\t牧野由依 \n",
      "玉川 徹 \t\t\t  |\t玉川徹 \n",
      "沖縄 市 \t\t\t  |\t沖縄市 \n",
      "小島 慶子 \t\t\t  |\t小島慶子 \n",
      "\n",
      "[test-mecab-ipadic-NEologd] : Finish..\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : Please check the list of differences in the upper part.\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : Do you want to install mecab-ipadic-NEologd? Type yes or no.\n",
      "[install-mecab-ipadic-NEologd] : OK. Let's install mecab-ipadic-NEologd.\n",
      "[install-mecab-ipadic-NEologd] : Start..\n",
      "[install-mecab-ipadic-NEologd] : /usr/lib/x86_64-linux-gnu/mecab/dic isn't current user's directory\n",
      "[install-mecab-ipadic-NEologd] : Sudo make install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
      "make[1]: Entering directory '/shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200820'\n",
      "make[1]: Nothing to be done for 'install-exec-am'.\n",
      "/bin/bash ./mkinstalldirs /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
      "mkdir /usr/lib/x86_64-linux-gnu/mecab\n",
      "mkdir /usr/lib/x86_64-linux-gnu/mecab/dic\n",
      "mkdir /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
      " /usr/bin/install -c -m 644 ./matrix.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/matrix.bin\n",
      " /usr/bin/install -c -m 644 ./char.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/char.bin\n",
      " /usr/bin/install -c -m 644 ./sys.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/sys.dic\n",
      " /usr/bin/install -c -m 644 ./unk.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/unk.dic\n",
      " /usr/bin/install -c -m 644 ./left-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/left-id.def\n",
      " /usr/bin/install -c -m 644 ./right-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/right-id.def\n",
      " /usr/bin/install -c -m 644 ./rewrite.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/rewrite.def\n",
      " /usr/bin/install -c -m 644 ./pos-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/pos-id.def\n",
      " /usr/bin/install -c -m 644 ./dicrc /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n",
      "make[1]: Leaving directory '/shared/momo/kashiwada/models/nlp/BERT/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200820'\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : Install completed.\n",
      "[install-mecab-ipadic-NEologd] : When you use MeCab, you can set '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd' as a value of '-d' option of MeCab.\n",
      "[install-mecab-ipadic-NEologd] : Usage of mecab-ipadic-NEologd is here.\n",
      "Usage:\n",
      "    $ mecab -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd ...\n",
      "\n",
      "[install-mecab-ipadic-NEologd] : Finish..\n",
      "[install-mecab-ipadic-NEologd] : Finish..\n"
     ]
    }
   ],
   "source": [
    "# !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
    "# !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新語辞書NEologdへのpathを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
    "path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
    "                           shell=True).communicate()[0]).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MeCabの動作確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新語辞書NEologdを使用しない場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私\tワタシ\t私\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "機械\tキカイ\t機械\t名詞-一般\t\t\n",
      "学習\tガクシュウ\t学習\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "m=MeCab.Tagger(\"-Ochasen\")\n",
    "\n",
    "text = \"私は機械学習が好きです。\"\n",
    "\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Ochasenを,\n",
    "-Owakatiにすると、分かち書きのみを出力\n",
    "-Oyomiにすると、読みのみを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は 機械 学習 が 好き です 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Owakati\")\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ワタシハキカイガクシュウガスキデス。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Oyomi\")\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新語辞書NEologdを使用する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私\tワタシ\t私\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "機械学習\tキカイガクシュウ\t機械学習\t名詞-固有名詞-一般\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Ochasen -d \"+str(path_neologd))  # NEologdへのパスを追加\n",
    "\n",
    "text = \"私は機械学習が好きです。\"\n",
    "\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私 は 機械学習 が 好き です 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m=MeCab.Tagger(\"-Owakati -d \"+str(path_neologd))  # NEologdへのパスを追加\n",
    "text_segmented = m.parse(text)\n",
    "print(text_segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 日本語版BERTの学習済みモデルと形態素解析を用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.modeling_bert import BertModel\n",
    "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99c2c5a1f7e44618734a53035094599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=257706.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをするtokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85de0e2413b4ff8a95b9270076cd1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f49058a12543eca6136c7a42eb1137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445021143.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# BERTの日本語学習済みパラメータのモデル\n",
    "model = BertModel.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "# 東北大学_日本語版の設定を確認\n",
    "config_japanese = BertConfig.from_pretrained('bert-base-japanese-whole-word-masking')\n",
    "print(config_japanese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日本語版BERTで文章を扱う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"会社をクビになった。\"\n",
    "text2 = \"テレワークばかりでクビが痛い。\"\n",
    "text3 = \"会社を解雇された。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '会社', 'を', 'クビ', 'に', 'なっ', 'た', '。', '[SEP]']\n",
      "tensor([[    2,   811,    11, 13700,     7,    58,    10,     8,     3]])\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをして、idに変換\n",
    "input_ids1 = tokenizer.encode(text1, return_tensors='pt')  # ptはPyTorchの略\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids1[0].tolist()))  # 文章\n",
    "print(input_ids1)  # id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'テレ', '##ワーク', 'ばかり', 'で', 'クビ', 'が', '痛', '##い', '。', '[SEP]']\n",
      "tensor([[    2,  5521,  3118,  4027,    12, 13700,    14,  4897, 28457,     8,\n",
      "             3]])\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをして、idに変換\n",
    "input_ids2 = tokenizer.encode(text2, return_tensors='pt')  # ptはPyTorchの略\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids2[0].tolist()))  # 文章\n",
    "print(input_ids2)  # id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '会社', 'を', '解雇', 'さ', 'れ', 'た', '。', '[SEP]']\n",
      "tensor([[   2,  811,   11, 7279,   26,   20,   10,    8,    3]])\n"
     ]
    }
   ],
   "source": [
    "# 分かち書きをして、idに変換\n",
    "input_ids3 = tokenizer.encode(text3, return_tensors='pt')  # ptはPyTorchの略\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids3[0].tolist()))  # 文章\n",
    "print(input_ids3)  # id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語ベクトルを求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# 日本語BERTモデルに入力\n",
    "result1 = model(input_ids1)\n",
    "\n",
    "print(result1[0].shape)\n",
    "print(result1[1].shape)\n",
    "\n",
    "# reult は、sequence_output, pooled_output, (hidden_states), (attentions)。\n",
    "# ただし、hidden_statesとattentionsはoptionalであり、標準では出力されない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語BERTモデルに入力\n",
    "result2 = model(input_ids2)\n",
    "result3 = model(input_ids3)\n",
    "\n",
    "word_vec1 = result1[0][0][3][:]  # 1つ目の文章の”クビ”（3番目）\n",
    "word_vec2 = result2[0][0][5][:]  # 2つ目の文章の”クビ”（5番目）\n",
    "word_vec3 = result3[0][0][3][:]  # 3つ目の文章の”解雇”（3番目）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コサイン類似度を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6647, grad_fn=<DivBackward0>)\n",
      "tensor(0.7841, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# コサイン類似度を求める\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "cos_sim_12 = cos(word_vec1, word_vec2)\n",
    "cos_sim_13 = cos(word_vec1, word_vec3)\n",
    "\n",
    "print(cos_sim_12)\n",
    "print(cos_sim_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
